{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd73995d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1b5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "CSV_PATH = \"dataset/e_waste_classification_dataset.csv\"  # <--- CHANGE THIS to your actual CSV path\n",
    "MODEL_SAVE_PATH = \"trained_models/text_classifier.pkl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47388ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataset/e_waste_classification_dataset.csv...\n",
      "Found columns: ['id', 'waste_description', 'waste_category']\n",
      "âœ… Loaded 1000 rows of data.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Create sample dataset if file doesn't exist\n",
    "if not os.path.exists(CSV_PATH):\n",
    "    os.makedirs(os.path.dirname(CSV_PATH), exist_ok=True)\n",
    "    sample_data = {\n",
    "        'waste_description': ['broken phone', 'old laptop', 'damaged tablet', 'faulty charger'],\n",
    "        'waste_category': ['electronics', 'electronics', 'electronics', 'electronics']\n",
    "    }\n",
    "    pd.DataFrame(sample_data).to_csv(CSV_PATH, index=False)\n",
    "    print(f\"âš ï¸ Created sample dataset at {CSV_PATH}\")\n",
    "\n",
    "print(f\"Loading data from {CSV_PATH}...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "print(\"Found columns:\", df.columns.tolist())\n",
    "\n",
    "# Rename columns to expected names\n",
    "df = df.rename(columns={\n",
    "    \"waste_description\": \"text\",\n",
    "    \"waste_category\": \"category\"\n",
    "})\n",
    "\n",
    "# Validate again\n",
    "required_cols = {\"text\", \"category\"}\n",
    "if not required_cols.issubset(df.columns):\n",
    "    raise ValueError(f\"CSV must contain columns: {required_cols}\")\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna(subset=[\"text\", \"category\"])\n",
    "\n",
    "print(f\"âœ… Loaded {len(df)} rows of data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "837b1a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution BEFORE split:\n",
      "category\n",
      "Hazardous & Lamps               258\n",
      "Large Equipment                 256\n",
      "Screens & Monitors              252\n",
      "Small IT & General Equipment    234\n",
      "Name: count, dtype: int64\n",
      "Unique labels: ['Hazardous & Lamps' 'Large Equipment' 'Screens & Monitors'\n",
      " 'Small IT & General Equipment']\n",
      "ðŸ“Š Training on 800 samples, Testing on 200 samples.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. SPLIT DATA (The Missing Part) ---\n",
    "# We use 80% of data to Train, and 20% to Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"Label distribution BEFORE split:\")\n",
    "print(df['category'].value_counts())\n",
    "print(\"Unique labels:\", df['category'].unique())\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], \n",
    "    df['category'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Training on {len(X_train)} samples, Testing on {len(X_test)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e0dff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Text Model...\n",
      "Testing Model...\n",
      "\n",
      "âœ… Model Accuracy: 100.00%\n",
      "\n",
      "Detailed Classification Report:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "           Hazardous & Lamps       1.00      1.00      1.00        45\n",
      "             Large Equipment       1.00      1.00      1.00        62\n",
      "          Screens & Monitors       1.00      1.00      1.00        36\n",
      "Small IT & General Equipment       1.00      1.00      1.00        57\n",
      "\n",
      "                    accuracy                           1.00       200\n",
      "                   macro avg       1.00      1.00      1.00       200\n",
      "                weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "Saving final model (trained on full dataset)...\n",
      "âœ… Text Model Saved as trained_models/text_waste_classifier.joblib\n"
     ]
    }
   ],
   "source": [
    "# --- 2. BUILD PIPELINE ---\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "    (\n",
    "        'tfidf',\n",
    "        TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),   # better context\n",
    "            min_df=2              # ignore ultra-rare words\n",
    "        )\n",
    "    ),\n",
    "    (\n",
    "        'clf',\n",
    "        LogisticRegression(\n",
    "            max_iter=300,\n",
    "            class_weight='balanced',  # ðŸ”¥ handles class imbalance\n",
    "            solver='lbfgs'\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "# --- 3. TRAIN ---\n",
    "print(\"Training Text Model...\")\n",
    "\n",
    "\n",
    "text_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# --- 4. TEST ---\n",
    "print(\"Testing Model...\")\n",
    "predictions = text_pipeline.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"\\nâœ… Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# --- 5. FINAL TRAIN ON FULL DATASET ---\n",
    "print(\"Saving final model (trained on full dataset)...\")\n",
    "text_pipeline.fit(df['text'], df['category'])\n",
    "\n",
    "# --- 6. SAVE ---\n",
    "import os, joblib\n",
    "\n",
    "MODEL_SAVE_PATH = \"trained_models/text_waste_classifier.joblib\"\n",
    "os.makedirs(\"trained_models\", exist_ok=True)\n",
    "\n",
    "joblib.dump(text_pipeline, MODEL_SAVE_PATH)\n",
    "print(f\"âœ… Text Model Saved as {MODEL_SAVE_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
